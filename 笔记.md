## 0. 资料

+ [PyTorch版YOLOv4代码](https://github.com/WongKinYiu/PyTorch_YOLOv4)；
+ [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934)；




## 1. Train Custom Data

### 1. Create dataset.yaml

```yaml
# train and val datasets (image directory or *.txt file with image paths)
train: ../person/images/train  # 118k images
val: ../person/images/val  # 5k images

# number of classes
nc: 1

# class names
names: ['person']
```



### 2. Create Labels

one `*.txt` file per image (if no objects in image, no `*.txt` file is required). The `*.txt` file specifications are:

- One row per object
- Each row is `class x_center y_center width height` format.
- Box coordinates must be in **normalized xywh** format (from 0 - 1). If your boxes are in pixels, divide `x_center` and `width` by image width, and `y_center` and `height` by image height.
- Class numbers are zero-indexed (start from 0).



### 3. Organize Directories

```
/person
	/images
		/train
			001.jpg
		/val
			007.jpg
/person
	/labels
		/train
			001.txt
		/val
			007.txt
```



### 4. 修改模型配置文件

+ https://github.com/AlexeyAB/Yolo_mark

+ https://github.com/WongKinYiu/PyTorch_YOLOv4/issues/161

```txt
kaishijeng commented on 18 Nov 2020
I noticed yolov4-paspp.cfg has set classes=80. My dataset has 10 classes, should I need to change from 80 to 10 in yolov4-paspp.cfg?
How about # of filters? According to darkent, it should be adjusted based on this formula:
((# no . of classes + 5) * 3)]

But I don't see (80+5)*3=255 in yolov4-paspp.cfg. Do you use different formula for # of filters in the cfg file?

Thanks,

@kaishijeng
 
Author
kaishijeng commented on 18 Nov 2020
I found where to change # of filters in cfg.
```

+ **以yolov4-pacsp.cfg为例**：

```yaml
[convolutional]
size=1
stride=1
pad=1
filters=18  #(no . of classes + 5) * 3
activation=linear


[yolo]
mask = 0,1,2
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=1  #no . of classes
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6


[convolutional]
size=1
stride=1
pad=1
filters=18  #(no . of classes + 5) * 3
activation=linear


[yolo]
mask = 3,4,5
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=1  #no . of classes
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6



[convolutional]
size=1
stride=1
pad=1
filters=18  #(no . of classes + 5) * 3
activation=linear


[yolo]
mask = 6,7,8
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=1  #no . of classes
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
```

